{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug-drug similarity for ctd dataset\n",
    "- https://www.nature.com/articles/nprot.2014.151\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_CUTOFF = 0 # Specify the TC cutoff. This option is useful if only the TCs of similar molecules above the established cutoff are needed. Otherwise, set T_CUTOFF=0 to provide all TC pair values.\n",
    "FINGERPRINT = 'MACCS' # Specify fingerprint (‘FP2’, ‘FP3’, ‘FP4’ or ‘MACCS’)\n",
    "MAINDIR = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_one_ChEMBL(FINGERPRINT, T_CUTOFF): \n",
    "    \"\"\"\n",
    "    This function calculates similarity of a drug with the other drugs \n",
    "    \n",
    "    Args: \n",
    "        FINGERPRINT: Fingerprint (‘FP2’, ‘FP3’, ‘FP4’ or ‘MACCS’)\n",
    "        T_CUTOFF: The established cutoff\n",
    "\n",
    "    Returns: A list of pairs of compounds and the relevant TC that quantifies the level of similarity between them.\n",
    "    \"\"\"\n",
    "    \n",
    "    input_temp = open(f'{MAINDIR}/temp_SMILES.txt', 'r')\n",
    "    print('pass-1')\n",
    "\n",
    "    # Create a dictionary of chemicals to be compared:\n",
    "    input_dict = dict()\n",
    "\n",
    "    # Read the input and the files previously created:\n",
    "    for line in input_temp:\n",
    "        newline = line.split()\n",
    "        if len(newline) != 2:\n",
    "            continue\n",
    "        smiles = newline[0]\n",
    "        id = newline[1]\n",
    "        input_dict[id] = smiles\n",
    "\n",
    "    input_temp.close()\n",
    "\n",
    "    # Open the results file (.csv file):\n",
    "    f = open(f'{MAINDIR}/TC_results.csv', 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['chemical1', 'chemical2', 'TC'])\n",
    "\n",
    "    # For each chemical in input list, calculate the TC between that chemical and all other chemicals in the\n",
    "    # input list using Open Babel:\n",
    "    for chemical1 in tqdm(input_dict):\n",
    "        babel_command = 'obabel -ismi -:\"%s\" /temp_SMILES.txt -ofpt -xf%s' %(input_dict[chemical1], FINGERPRINT)\n",
    "        output = subprocess.Popen(babel_command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    # Read and parse output from Open Babel:\n",
    "    TC_list = []\n",
    "    TC_list_tmp = []\n",
    "\n",
    "    while True:\n",
    "        line = output.stdout.readline().decode('ascii')\n",
    "        if line != '':\n",
    "            newline = re.split('>|=', line)\n",
    "           \n",
    "\n",
    "            if len(newline) > 2:\n",
    "                id_catcher = newline[1].split()\n",
    "                chemical2 = id_catcher[0]\n",
    "                TC = float(newline[2])\n",
    "                TC_list.append((chemical2, TC))\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Write the TCs exceeding the cutoff to the output file\n",
    "    for chemical2, TC in TC_list:\n",
    "        if TC >= T_CUTOFF and chemical1 != chemical2:\n",
    "            writer.writerow([chemical1, chemical2, TC])\n",
    "            TC_list_tmp.append((chemical1, chemical2, TC))\n",
    "            \n",
    "    del TC_list\n",
    "    f.close()\n",
    "    \n",
    "    return TC_list_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SMILES_main = pd.read_csv(f'{MAINDIR}/temp_SMILES_main.txt', sep='\\t', header=None)\n",
    "# a copy of all SMILES. It will be updated to create the DDS matrix\n",
    "df_SMILES_main.to_csv(f'{MAINDIR}/temp_SMILES.txt',sep='\\t', index=False, header=False)\n",
    "SMILES_id = df_SMILES_main[0].to_list()[::-1]\n",
    "print(f\"Number of drug: {len(SMILES_id)}\\n\")\n",
    "\n",
    "df_SMILES_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "TC_list_final = [] # All drug-drug similarity\n",
    "for c in SMILES_id[:-1]:\n",
    "    i += 1\n",
    "    TC_list_tmp = sim_one_ChEMBL(FINGERPRINT, T_CUTOFF)\n",
    "    TC_list_final.append(TC_list_tmp)\n",
    "    \n",
    "    # After calculating the drug (c) similarity, it will be removed from list (we have already added the similarity of durg (c) with all drugs) \n",
    "    df = pd.read_csv(f'{MAINDIR}/temp_SMILES.txt', skipfooter = 1, engine='python',sep='\\t', header=None)\n",
    "    df.to_csv(f'{MAINDIR}/temp_SMILES.txt',sep='\\t', index=False, header=False)\n",
    "    print(i)\n",
    "    \n",
    "    # Because the data is big, it is collected gradually \n",
    "    if (i % 100 == 0) | (i>len(SMILES_id)-10):\n",
    "        df_TC_list_final = pd.DataFrame(list(chain(*TC_list_final)))\n",
    "        df_TC_list_final[0] = df_TC_list_final[0].str.replace('CHEMBL', '')\n",
    "        df_TC_list_final[1] = df_TC_list_final[1].str.replace('CHEMBL', '')\n",
    "        df_TC_list_final.to_csv(f'{MAINDIR}/DDS_known_ChEMBLid{i}_T{len(SMILES_id)}.csv')\n",
    "        #df_TC_list_final.to_csv(f'/data/Elmira_Data/ChEMBL/DDS_known_ChEMBLid{i}_T{len(SMILES_id)}.txt',sep='\\t', index=False, header=False)\n",
    "        #TC_list_final.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the last file has all similarities\n",
    "DDS_tmp = pd.read_csv(f'{MAINDIR}/DDS_known_ChEMBLid289_T290.csv', index_col=0)\n",
    "DDS_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDS = DDS_tmp.rename(columns={'0':'from','1':'to', '2':'weight'})\n",
    "with open(f\"{MAINDIR}/DDS.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(DDS, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
