{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import itertools\n",
    "from sklearn.manifold import TSNE\n",
    "from sknetwork.data import karate_club, painters, movie_actor\n",
    "from sknetwork.clustering import Louvain, BiLouvain, modularity, bimodularity\n",
    "from sknetwork.linalg import normalize\n",
    "from sknetwork.utils import bipartite2undirected, membership_matrix\n",
    "from sknetwork.visualization import svg_graph, svg_digraph, svg_bigraph\n",
    "from sknetwork.hierarchy import LouvainHierarchy, BiLouvainHierarchy\n",
    "from sknetwork.hierarchy import dasgupta_score, dasgupta_cost\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans, FeatureAgglomeration, AffinityPropagation, MeanShift, SpectralClustering, AgglomerativeClustering, AgglomerativeClustering, DBSCAN, Birch\n",
    "\n",
    "import pickle\n",
    "import graphviz\n",
    "from xgboost import plot_tree\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import gensim\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from ggplot import *\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from matplotlib import rc\n",
    "\n",
    "import scipy\n",
    "\n",
    "import pickle\n",
    "import shap\n",
    "import random\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "\n",
    "from ggplot import *\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    matthews_corrcoef,\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    fbeta_score\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot\n",
    "import networkx as nx\n",
    "import networkx\n",
    "import community\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from community import community_louvain\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import scipy\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ggplot import *\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    silhouette_score,\n",
    "    silhouette_samples,\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    "    roc_curve,\n",
    "    matthews_corrcoef,\n",
    "    auc,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('drugId2numId_nod2vec.pkl', 'rb') as f:\n",
    "    drugId2numId_nod2vec = pickle.load(f)\n",
    "with open('diseaseId2numId_nod2vec.pkl', 'rb') as f:\n",
    "    diseaseId2numId_nod2vec = pickle.load(f)\n",
    "with open('target2name.pkl', 'rb') as f:\n",
    "    target2name = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease2name= pd.Series('disease', index=list(diseaseId2numId_nod2vec.values())).to_dict()\n",
    "drug2name = pd.Series('drug', index=list(drugId2numId_nod2vec.values())).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_id = {**drug2name, **disease2name, **target2name}\n",
    "pd.DataFrame(dict_id.items(), columns=['id', 'type'])['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('DTI.pkl', 'rb') as f:\n",
    "    DTI = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('all_nod2vec.pkl', 'rb') as f:\n",
    "    all_nod2vec = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('all_nod2vec_new.pkl', 'rb') as f:\n",
    "    all_nod2vec_new = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = False\n",
    "df = all_nod2vec.copy()\n",
    "\n",
    "######    ######    ######    ######    ######    ######    ######    ######    ######    ######    ######    ######\n",
    "\n",
    "df = df[df['weight']!=0]\n",
    "df = df.drop(columns= ['Type_Interaction'])\n",
    "\n",
    "os.chdir(\"nod2vec\")\n",
    "df.to_csv('edglist_all.edgelist', sep=' ', index=False, header=False)\n",
    "os.chdir(\"EEG_pathway_Embedding\")\n",
    "\n",
    "if mapping:\n",
    "    # nod2vec (for drug)\n",
    "    os.system(f'PYTHONHASHSEED=10 python2 node2vec/src/main.py --workers 8 --input dim10_all_plus.emb --weighted --dimensions 10')\n",
    "\n",
    "embeddings_all = pd.read_csv('dim10_all_plus.emb', sep=' ', skiprows=[0], header=None, index_col=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_all_id = embeddings_all.copy()\n",
    "embeddings_all_id['type']= embeddings_all.index.map(dict_id)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(embeddings_all_id.drop(columns=['type']).values)\n",
    "\n",
    "\n",
    "embeddings_all_id['PCA-1'] = pca_result[:,0]\n",
    "embeddings_all_id['PCA-2'] = pca_result[:,1]\n",
    "\n",
    "chart = ggplot(embeddings_all_id, aes(x='PCA-1', y='PCA-2',  color='factor(type)') ) \\\n",
    "    + geom_point(size=120, alpha=0.8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# removing nodes that we do not have embedding vectors\n",
    "new_DTI = DTI[DTI['to'].isin(list(embeddings_all.index))]\n",
    "new_DTI = new_DTI[new_DTI['from'].isin(list(embeddings_all.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_DTI['label'] = new_DTI[['S1','S2','S3','S4','S5','S6']].values.tolist()\n",
    "selected_type = ['increases^expression','decreases^expression','decreases^reaction','increases^reaction', 'increases^activity','decreases^activity', 'negative_DTI']\n",
    "for i in range (0, len(new_DTI)):\n",
    "    new_DTI['label'].iloc[i] = list(set(new_DTI['label'].iloc[i])& set(selected_type))\n",
    "    \n",
    "print (new_DTI['Type_Interaction'].value_counts())\n",
    "\n",
    "new_DTI = new_DTI[['from','to', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concating(df, embedding):\n",
    "    \"\"\"\n",
    "    This function concats drugs and targets vectors\n",
    "    \n",
    "    Args: \n",
    "        df: A DataFrame of drug-target interactions\n",
    "        embedding: A DataFrame of embedded vectors for each drug and target\n",
    "        \n",
    "    Returns: A DataFrame of drug-target interaction vectors\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    for idx, row in df.iterrows():\n",
    "        from_vector = embedding.loc[row['from']]\n",
    "        to_vector = embedding.loc[row['to']]\n",
    "        features = from_vector.append(to_vector).reset_index(drop=True)\n",
    "        features = features.append(row)\n",
    "        dataset.append(features)\n",
    "\n",
    "    df_final = pd.DataFrame(dataset)\n",
    "    df_final.drop(columns=['from', 'to'], inplace=True)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = concating(new_DTI, embeddings_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create matrix of labels as 0 and 1 (one hot encoder)\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "df_label = pd.DataFrame(mlb.fit_transform(df_final['label']), columns=mlb.classes_, index=df_final.index)\n",
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add new label format to gene/drug interaction dataframe\n",
    "df_interaction_newLabel = pd.concat([df_final.drop(columns=['label']), df_label], axis=1).drop_duplicates()\n",
    "df_interaction_newLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interaction_newLabel_PAC = df_interaction_newLabel.drop(columns= ['increases^expression','decreases^expression','decreases^reaction','increases^reaction', 'increases^activity','decreases^activity'])\n",
    "df_interaction_newLabel_PAC['type'] = df_interaction_newLabel_PAC['negative_DTI']\n",
    "df_interaction_newLabel_PAC = df_interaction_newLabel_PAC.drop(columns=['negative_DTI']).drop_duplicates()\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(df_interaction_newLabel_PAC.drop(columns=['type']).values)\n",
    "\n",
    "\n",
    "df_interaction_newLabel_PAC['PCA-1'] = pca_result[:,0]\n",
    "df_interaction_newLabel_PAC['PCA-2'] = pca_result[:,1]\n",
    "\n",
    "chart = ggplot(df_interaction_newLabel_PAC, aes(x='PCA-1', y='PCA-2',  color='factor(type)') ) \\\n",
    "    + geom_point(size=120, alpha=0.8) \n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report\n",
    "for i in selected_type:\n",
    "    n_label = df_interaction_newLabel[i].sum()\n",
    "    n_rest = len(df_interaction_newLabel)- n_label\n",
    "    print (f'number of {i}: {n_label} VS. rest: {n_rest}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## seperate features (as x) and labels (as y)\n",
    "def get_data(df_train, label, all_labels):\n",
    "    df_interaction_new = df_train.copy()\n",
    "    df_interaction_new['label'] = df_interaction_new[label]\n",
    "    df_interaction_new.drop(columns=list(all_labels), inplace=True)\n",
    "    print(df_interaction_new['label'].value_counts())\n",
    "    \n",
    "    X = df_interaction_new.drop(columns=['label'])\n",
    "    y = pd.DataFrame(df_interaction_new['label'])\n",
    "    \n",
    "    return X, y.values.ravel()\n",
    "\n",
    "def get_sample_weight(y_train):\n",
    "    weight_ratio = float(len(y_train[y_train == 0]))/float(len(y_train[y_train == 1]))\n",
    "    \n",
    "    return weight_ratio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
