{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import itertools\n",
    "from sklearn.manifold import TSNE\n",
    "from sknetwork.data import karate_club, painters, movie_actor\n",
    "from sknetwork.clustering import Louvain, BiLouvain, modularity, bimodularity\n",
    "from sknetwork.linalg import normalize\n",
    "from sknetwork.utils import bipartite2undirected, membership_matrix\n",
    "from sknetwork.visualization import svg_graph, svg_digraph, svg_bigraph\n",
    "from sknetwork.hierarchy import LouvainHierarchy, BiLouvainHierarchy\n",
    "from sknetwork.hierarchy import dasgupta_score, dasgupta_cost\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans, FeatureAgglomeration, AffinityPropagation, MeanShift, SpectralClustering, AgglomerativeClustering, AgglomerativeClustering, DBSCAN, Birch\n",
    "import math\n",
    "import pickle\n",
    "import graphviz\n",
    "from xgboost import plot_tree\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import gensim\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from ggplot import *\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from matplotlib import rc\n",
    "\n",
    "import scipy\n",
    "\n",
    "import pickle\n",
    "import shap\n",
    "import random\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "\n",
    "from ggplot import *\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    matthews_corrcoef,\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    fbeta_score\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot\n",
    "import networkx as nx\n",
    "import networkx\n",
    "import community\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from community import community_louvain\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import scipy\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ggplot import *\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    silhouette_score,\n",
    "    silhouette_samples,\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    "    roc_curve,\n",
    "    matthews_corrcoef,\n",
    "    auc,\n",
    "    balanced_accuracy_score\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('drugId2numId_nod2vec.pkl', 'rb') as f:\n",
    "    drugId2numId_nod2vec = pickle.load(f)\n",
    "with open('diseaseId2numId_nod2vec.pkl', 'rb') as f:\n",
    "    diseaseId2numId_nod2vec = pickle.load(f)\n",
    "with open('target2name.pkl', 'rb') as f:\n",
    "    target2name = pickle.load(f)   \n",
    "with open('drug_cut2chem.pkl', 'rb') as f:\n",
    "    drug_cut2chem = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChEMBL = pd.read_csv('CHEMBL27_find_negative.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChEMBL_ph4 = ChEMBL[ChEMBL['Molecule Max Phase']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chmble2drugname = pd.Series(ChEMBL_ph4['Molecule Name'].values, index=ChEMBL_ph4['Molecule ChEMBL ID']).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllDisGene = pd.read_pickle('CTD_genes_diseases.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_entrez_geneid = pd.read_csv(\"entrez_geneid.csv\").dropna(subset=['entrezgene'])\n",
    "df_entrez =  df_entrez_geneid[['symbol','entrezgene']]\n",
    "df_entrez.index = df_entrez_geneid['entrezgene']\n",
    "df_entrez = df_entrez.drop(columns=['entrezgene'])\n",
    "entrezgene_dic = df_entrez.to_dict()['symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entrez_geneid2 = pd.read_csv(\"selected_uniport_seq.csv\")[['id','Gene names']]\n",
    "df_entrez_geneid2.index = df_entrez_geneid2['id']\n",
    "df_entrez_geneid2 = df_entrez_geneid2.drop(columns=['id'])\n",
    "entrezgene_dic2 = df_entrez_geneid2.to_dict()['Gene names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease2name= pd.Series('disease', index=list(diseaseId2numId_nod2vec.values())).to_dict()\n",
    "drug2name = pd.Series('drug', index=list(drugId2numId_nod2vec.values())).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_id = {**drug2name, **disease2name, **target2name}\n",
    "pd.DataFrame(dict_id.items(), columns=['id', 'type'])['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('final_interactions/DTI.pkl', 'rb') as f:\n",
    "    DTI = pickle.load(f).reset_index(drop=True)\n",
    "    \n",
    "DTI_tmp_index = DTI[['from','to']].drop_duplicates().index\n",
    "DTI = DTI[DTI.index.isin(DTI_tmp_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_DTI = pd.read_csv('negative_int.csv',index_col=0)\n",
    "negative_DTI ['from'] = negative_DTI['Chembl'].str.replace('CHEMBL', '').astype(int).map(drugId2numId_nod2vec)\n",
    "negative_DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('all_nod2vec.pkl', 'rb') as f:\n",
    "    all_nod2vec = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numId2drugId = pd.Series(drugId2numId_nod2vec.keys(), index=drugId2numId_nod2vec.values()).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dds = all_nod2vec[all_nod2vec['Type_Interaction']=='DDS']\n",
    "df_dds['from'] = df_dds['from'].map(numId2drugId).apply(lambda x: f\"CHEMBL{x}\")\n",
    "df_dds['to'] = df_dds['to'].map(numId2drugId).apply(lambda x: f\"CHEMBL{x}\")\n",
    "df_dds[['from','to','weight']].to_csv('DDS_with_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pps = all_nod2vec[all_nod2vec['Type_Interaction']=='PPS']\n",
    "df_pps['from'] = df_pps['from'].map(entrezgene_dic2)\n",
    "df_pps['to'] = df_pps['to'].map(entrezgene_dic2)\n",
    "df_pps[['from','to','weight']].to_csv('PPS_with_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('all_nod2vec_new.pkl', 'rb') as f:\n",
    "    all_nod2vec_new = pickle.load(f)\n",
    "all_nod2vec_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = False\n",
    "df = all_nod2vec.copy()\n",
    "\n",
    "######    ######    ######    ######    ######    ######    ######    ######    ######    ######    ######    ######\n",
    "\n",
    "df = df[df['weight']!=0]\n",
    "df = df.drop(columns= ['Type_Interaction'])\n",
    "\n",
    "os.chdir(\"nod2vec\")\n",
    "df.to_csv('edglist_list.edgelist', sep=' ', index=False, header=False)\n",
    "os.chdir(\"KEEG_pathway_Embedding\")\n",
    "\n",
    "if mapping:\n",
    "    # nod2vec (for drug)\n",
    "    os.system(f'PYTHONHASHSEED=10 python2 node2vec/src/main.py --workers 8 --input edglist_list.edgelist --output dim100.emb --weighted --dimensions 100')\n",
    "\n",
    "embeddings_all = pd.read_csv('dim100.emb', sep=' ', skiprows=[0], header=None, index_col=0)  \n",
    "embeddings_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_label(X, y):\n",
    "    X_pca = X.copy()\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(X_pca.values)\n",
    "    \n",
    "    X_pca['PCA-1'] = pca_result[:,0]\n",
    "    X_pca['PCA-2'] = pca_result[:,1]\n",
    "    X_pca['type'] = y\n",
    "    \n",
    "    plt = ggplot(X_pca, aes(x='PCA-1', y='PCA-2',  color='factor(type)') ) \\\n",
    "    + geom_point(size=100, alpha=0.8)\n",
    "    \n",
    "    print(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_decimals_up(number:float, decimals:int=2):\n",
    "    \"\"\"\n",
    "    Returns a value rounded up to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    if not isinstance(decimals, int):\n",
    "        raise TypeError(\"decimal places must be an integer\")\n",
    "    elif decimals < 0:\n",
    "        raise ValueError(\"decimal places has to be 0 or more\")\n",
    "    elif decimals == 0:\n",
    "        return math.ceil(number)\n",
    "\n",
    "    factor = 10 ** decimals\n",
    "    return math.ceil(number * factor) / factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_all_id = embeddings_all.copy()\n",
    "embeddings_all_id['type']= embeddings_all.index.map(dict_id)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(embeddings_all_id.drop(columns=['type']).dropna().values)\n",
    "\n",
    "\n",
    "embeddings_all_id['PCA-1'] = pca_result[:,0]\n",
    "embeddings_all_id['PCA-2'] = pca_result[:,1]\n",
    "embeddings_all_id['PCA-3'] = pca_result[:,2]\n",
    "\n",
    "\n",
    "chart = ggplot(embeddings_all_id.dropna(), aes(x='PCA-1', y='PCA-2',  color='factor(type)') ) \\\n",
    "    + geom_point(size=120, alpha=0.8) \n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alicia_gene_name = embeddings_all_id[embeddings_all_id['type']=='target'][['type']]\n",
    "entrezgene_dic2[8536] = 'CAMK1'\n",
    "entrezgene_dic2[5753] = 'PTK6'\n",
    "entrezgene_dic2[57172] = 'CAMK1G'\n",
    "entrezgene_dic2[23678] = 'SGK3'\n",
    "entrezgene_dic2[3303] = 'HSPA1A'\n",
    "Alicia_gene_name['gene name'] = Alicia_gene_name.index.map(entrezgene_dic2)\n",
    "Alicia_gene_name['entrez gene'] = Alicia_gene_name.index\n",
    "Alicia_gene_name[['entrez gene', 'gene name']].to_csv('gene_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def community_layout(g, partition):\n",
    "    \"\"\"\n",
    "    Compute the layout for a modular graph.\n",
    "\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    g -- networkx.Graph or networkx.DiGraph instance\n",
    "        graph to plot\n",
    "\n",
    "    partition -- dict mapping int node -> int community\n",
    "        graph partitions\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pos -- dict mapping int node -> (float x, float y)\n",
    "        node positions\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    pos_communities = _position_communities(g, partition, scale=3.)\n",
    "\n",
    "    pos_nodes = _position_nodes(g, partition, scale=1.)\n",
    "\n",
    "    # combine positions\n",
    "    pos = dict()\n",
    "    for node in g.nodes():\n",
    "        pos[node] = pos_communities[node] + pos_nodes[node]\n",
    "\n",
    "    return pos\n",
    "\n",
    "def _position_communities(g, partition, **kwargs):\n",
    "\n",
    "    # create a weighted graph, in which each node corresponds to a community,\n",
    "    # and each edge weight to the number of edges between communities\n",
    "    between_community_edges = _find_between_community_edges(g, partition)\n",
    "\n",
    "    communities = set(partition.values())\n",
    "    hypergraph = nx.DiGraph()\n",
    "    hypergraph.add_nodes_from(communities)\n",
    "    for (ci, cj), edges in between_community_edges.items():\n",
    "        hypergraph.add_edge(ci, cj, weight=len(edges))\n",
    "\n",
    "    # find layout for communities\n",
    "    pos_communities = nx.spring_layout(hypergraph, **kwargs)\n",
    "\n",
    "    # set node positions to position of community\n",
    "    pos = dict()\n",
    "    for node, community in partition.items():\n",
    "        pos[node] = pos_communities[community]\n",
    "\n",
    "    return pos\n",
    "\n",
    "def _find_between_community_edges(g, partition):\n",
    "\n",
    "    edges = dict()\n",
    "\n",
    "    for (ni, nj) in g.edges():\n",
    "        ci = partition[ni]\n",
    "        cj = partition[nj]\n",
    "\n",
    "        if ci != cj:\n",
    "            try:\n",
    "                edges[(ci, cj)] += [(ni, nj)]\n",
    "            except KeyError:\n",
    "                edges[(ci, cj)] = [(ni, nj)]\n",
    "\n",
    "    return edges\n",
    "\n",
    "def _position_nodes(g, partition, **kwargs):\n",
    "    \"\"\"\n",
    "    Positions nodes within communities.\n",
    "    \"\"\"\n",
    "\n",
    "    communities = dict()\n",
    "    for node, community in partition.items():\n",
    "        try:\n",
    "            communities[community] += [node]\n",
    "        except KeyError:\n",
    "            communities[community] = [node]\n",
    "\n",
    "    pos = dict()\n",
    "    for ci, nodes in communities.items():\n",
    "        subgraph = g.subgraph(nodes)\n",
    "        pos_subgraph = nx.spring_layout(subgraph, **kwargs)\n",
    "        pos.update(pos_subgraph)\n",
    "\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nod2vec_new = all_nod2vec[all_nod2vec['weight']>=0.00][['from','to','weight']]\n",
    "all_nod2vec_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target2cluster = pd.Series(embeddings_all_id['type'].map({'drug':0,'target':1,'disease':2}).values, index= embeddings_all_id.index).to_dict()\n",
    "target2cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_all_id[embeddings_all_id['type'].isna()]\n",
    "target2cluster[100507538] = 2\n",
    "target2cluster[100507539 ]= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {0: \"#E07F80\", 1: \"#3E7274\", 2: \"#F2B342\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters PPS network\n",
    "edgeList_pps = all_nod2vec_new.values.tolist()\n",
    "G = networkx.Graph()\n",
    "weights = []\n",
    "\n",
    "for i in range(len(edgeList_pps)):\n",
    "    G.add_edge(edgeList_pps[i][0], edgeList_pps[i][1], weight=edgeList_pps[i][2])\n",
    "    weights.append(edgeList_pps[i][2])\n",
    "    \n",
    "A = networkx.adjacency_matrix(G).A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_col = list(embeddings_all_id['type'].map({'drug':0,'target':1,'disease':2}).map({0: \"#E07F80\", 1: \"#3E7274\", 2: \"#F2B342\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_all_id_1 = embeddings_all_id.copy()\n",
    "embeddings_all_id_1['type1']= embeddings_all_id['type'].map({'drug':0,'target':1,'disease':2}).map({0: \"#E07F80\", 1: \"#3E7274\", 2: \"#F2B342\"})\n",
    "embeddings_all_id_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "sns.set(style = \"white\")\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "x = embeddings_all_id['PCA-1']\n",
    "y = embeddings_all_id['PCA-2']\n",
    "z = embeddings_all_id['PCA-3']\n",
    "\n",
    "cmap_dict = {0: \"#E07F80\", 1: \"#3E7274\", 2: \"#F2B342\"}\n",
    "cmap = ListedColormap(list(cmap_dict.values()))\n",
    "\n",
    "ax.set_xlabel(\" \")\n",
    "ax.set_ylabel(\" \")\n",
    "ax.set_zlabel(\" \")\n",
    "\n",
    "sc = ax.scatter(x, y, z, s=40,cmap=cmap, c=embeddings_all_id['type'].map({'drug':0,'target':1,'disease':2}), marker='o', alpha=1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# removing nodes that we do not have embedding vectors\n",
    "new_DTI = DTI[DTI['to'].isin(list(embeddings_all.index))]\n",
    "new_DTI = new_DTI[new_DTI['from'].isin(list(embeddings_all.index))]\n",
    "new_DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_DTI['label'] = new_DTI[['S1','S2','S3','S4','S5','S6']].values.tolist()\n",
    "selected_type = ['increases^expression','decreases^expression','decreases^reaction','increases^reaction', 'increases^activity','decreases^activity']\n",
    "for i in range (0, len(new_DTI)):\n",
    "    new_DTI['label'].iloc[i] = list(set(new_DTI['label'].iloc[i])& set(selected_type))\n",
    "    \n",
    "print (new_DTI['Type_Interaction'].value_counts())\n",
    "\n",
    "new_DTI = new_DTI[['from','to','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alicia_gene_name = new_DTI.copy()\n",
    "Alicia_gene_name['gene name']= Alicia_gene_name['to'].map(entrezgene_dic2)\n",
    "Alicia_gene_name['entrez gene'] = Alicia_gene_name['to']\n",
    "Alicia_gene_name[['entrez gene','gene name']].drop_duplicates().to_csv('gene_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alicia_gene_name['entrez gene'] = Alicia_gene_name.index\n",
    "Alicia_gene_name[['entrez gene', 'gene name']].to_csv('gene_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concating(df, embedding):\n",
    "    \"\"\"\n",
    "    This function concats drugs and targets vectors\n",
    "    \n",
    "    Args: \n",
    "        df: A DataFrame of drug-target interactions\n",
    "        embedding: A DataFrame of embedded vectors for each drug and target\n",
    "        \n",
    "    Returns: A DataFrame of drug-target interaction vectors\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    for idx, row in df.iterrows():\n",
    "        from_vector = embedding.loc[row['from']]\n",
    "        to_vector = embedding.loc[row['to']]\n",
    "        features = from_vector.append(to_vector).reset_index(drop=True)\n",
    "        features = features.append(row)\n",
    "        dataset.append(features)\n",
    "\n",
    "    df_final = pd.DataFrame(dataset)\n",
    "    df_final.drop(columns=['from', 'to'], inplace=True)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_negative_DTI = negative_DTI[['from','to']]\n",
    "new_negative_DTI['label'] = [['negative_DTI']] * len(new_negative_DTI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_final = concating(new_negative_DTI, embeddings_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = concating(new_DTI, embeddings_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create matrix of labels as 0 and 1 (one hot encoder)\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "df_label = pd.DataFrame(mlb.fit_transform(df_final['label']), columns=mlb.classes_, index=df_final.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_new  = df_label.copy()\n",
    "df_label_new['sum'] = df_label.sum(axis=1) \n",
    "df_label_new['sum'].value_counts()\n",
    "df_label_new ['label'] = df_final['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_label = []\n",
    "for i in df_label_new.index:\n",
    "    if df_label_new.loc[[i]]['sum'][i]== 1:\n",
    "        list_label.insert(len(list_label),str(df_label_new.loc[[i]]['label'][i][0]))\n",
    "    else:\n",
    "        list_label.insert(len(list_label),df_label_new.loc[[i]]['sum'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_new['final'] = list_label\n",
    "df_label_new['final'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add new label format to gene/drug interaction dataframe\n",
    "df_interaction_newLabel = pd.concat([df_final.drop(columns=['label']), df_label], axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in  selected_type:\n",
    "    print(i)\n",
    "    sns.set(style = \"white\")\n",
    "    color_dict = {'decreases^activity':'#5C5D9E',\n",
    "     'decreases^expression':'#317EC2',\n",
    "     'decreases^reaction':'#5AAA46',\n",
    "     'increases^activity':'#C03830',\n",
    "     'increases^expression':'#E7872B',\n",
    "     'increases^reaction':'#E9C61D'}\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111, projection = '3d')\n",
    "    df_pca = df_interaction_newLabel.copy()\n",
    "    pca_result = pca.fit_transform(df_interaction_newLabel.drop(columns=selected_type).values)\n",
    "\n",
    "    x = pca_result[:,0]\n",
    "    y = pca_result[:,1]\n",
    "    z = pca_result[:,2]\n",
    "    df_pca['type']= df_pca[i]\n",
    "    \n",
    "    color = color_dict[i]\n",
    "\n",
    "    cmap_dict = {0: \"silver\", 1: color}\n",
    "    cmap = ListedColormap(list(cmap_dict.values()))\n",
    "\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_zlabel(\"\")\n",
    "\n",
    "    sc = ax.scatter(x, y, z, s=40, cmap=cmap, c=df_pca['type'], marker='o', alpha=1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in  selected_type:   \n",
    "    df_pca = df_interaction_newLabel.copy()\n",
    "    pca = PCA(n_components=3)\n",
    "    pca_result = pca.fit_transform(df_interaction_newLabel.drop(columns=selected_type).values)\n",
    "\n",
    "\n",
    "    df_pca['PCA-1'] = pca_result[:,0]\n",
    "    df_pca['PCA-2'] = pca_result[:,1]\n",
    "    df_pca['PCA-3'] = pca_result[:,2]\n",
    "\n",
    "    df_pca['type']= df_pca[i]\n",
    "    chart = ggplot(df_pca, aes(x='PCA-1', y='PCA-3',  color='factor(type)') ) \\\n",
    "        + geom_point(size=120, alpha=0.8) \n",
    "\n",
    "    chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing noise labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_noise = list(df_interaction_newLabel.loc[(df_interaction_newLabel['decreases^expression']==1) & (df_interaction_newLabel['increases^expression']==1), :].index)\n",
    "reaction_noise =  list(df_interaction_newLabel.loc[(df_interaction_newLabel['decreases^reaction']==1) & (df_interaction_newLabel['increases^reaction']==1), :].index)\n",
    "activity_noise =  list(df_interaction_newLabel.loc[(df_interaction_newLabel['decreases^activity']==1) & (df_interaction_newLabel['increases^activity']==1), :].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_noise = expression_noise+reaction_noise+activity_noise\n",
    "print(f'number of noise: {len(all_noise)}')\n",
    " \n",
    "df_interaction_newLabel = df_interaction_newLabel.drop(all_noise)\n",
    "df_interaction_newLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some DTI has more than one type of interaction\n",
    "num_all_interaction = 0\n",
    "for i in selected_type:\n",
    "    tmp1 = df_interaction_newLabel[i].sum()\n",
    "    num_all_interaction = num_all_interaction+tmp1\n",
    "num_all_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in selected_type:\n",
    "    n_label = df_interaction_newLabel[i].sum()\n",
    "    n_rest = len(df_interaction_newLabel)- n_label\n",
    "    print (f'number of {i}: {n_label} VS. rest: {n_rest}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## seperate features (as x) and labels (as y)\n",
    "def get_data(df_train, label, all_labels):\n",
    "    df_interaction_new = df_train.copy()\n",
    "    df_interaction_new['label'] = df_interaction_new[label]\n",
    "    df_interaction_new.drop(columns=list(all_labels), inplace=True)\n",
    "    print(df_interaction_new['label'].value_counts())\n",
    "    \n",
    "    X = df_interaction_new.drop(columns=['label'])\n",
    "    y = pd.DataFrame(df_interaction_new['label'])\n",
    "    \n",
    "    return X, y.values.ravel()\n",
    "\n",
    "def get_sample_weight(y_train):\n",
    "    weight_ratio = float(len(y_train[y_train == 0]))/float(len(y_train[y_train == 1]))\n",
    "    \n",
    "    return weight_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y, y_pred):\n",
    "    result = {}\n",
    "    result['accuracy'] = accuracy_score(y, y_pred)\n",
    "\n",
    "    try:\n",
    "        result['ROC'] = metrics.roc_auc_score(y, y_pred,average='binary')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    result['precision'] = precision_score(y, y_pred, average='binary')   \n",
    "    result['recall'] = recall_score(y, y_pred, average='binary')   \n",
    "    result['f1_score'] = f1_score(y, y_pred, average='binary')  \n",
    "    try:\n",
    "        TN = confusion_matrix(y, y_pred)[0,0]\n",
    "        FP = confusion_matrix(y, y_pred)[0,1]\n",
    "        specifity = TN/(TN+FP)\n",
    "        dic['specifity'] = specifity\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    result['confusion_matrix'] = confusion_matrix(y, y_pred)\n",
    "    \n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y, y_pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        result['fpr'] = fpr\n",
    "        result['tpr'] = tpr\n",
    "        result['roc_auc'] = roc_auc\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to train-validation and external test \n",
    "DTI_external_test = df_interaction_newLabel.sample(frac = 0.1)\n",
    "DTI_new = df_interaction_newLabel.drop(DTI_external_test.index)\n",
    "print (f'DTI: {len(df_interaction_newLabel)}')\n",
    "print (f'DTI_external_test: {len(DTI_external_test)}')\n",
    "print (f'DTI_train_internal_test: {len(DTI_new)}')\n",
    "DTI_external_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_results(df, print_results):\n",
    "    \"\"\"\n",
    "    This function create dictinary to reports results \n",
    "    \n",
    "    Args: \n",
    "        df: A DataFrame of results for diffrenet runs/CV\n",
    "    Returns: \n",
    "        dic_results: dictionary of all results\n",
    "    \"\"\"\n",
    "    \n",
    "    dic_results = {}\n",
    "    \n",
    "    for label in selected_type:\n",
    "        \n",
    "        df_a_labl = df[df['clf_name']==label]\n",
    "        if print_results:\n",
    "            print(f'============  {label}  ============')\n",
    "            print(f\"Mean accuracy: {df_a_labl['accuracy'].mean()} ({df_a_labl['accuracy'].std()})\")\n",
    "            print(f\"Mean ROC: {df_a_labl['roc_auc'].mean()}({df_a_labl['roc_auc'].std()})\")\n",
    "            print(f\"Mean f1_score: {df_a_labl['f1_score'].mean()}({df_a_labl['f1_score'].std()})\")\n",
    "            print(f\"Mean precision: {df_a_labl['precision'].mean()}({df_a_labl['precision'].std()})\")\n",
    "            print(f\"Mean recall: {df_a_labl['recall'].mean()}({df_a_labl['recall'].std()})\\n\")\n",
    "        \n",
    "        dic_results[label] = {'accuracy':df_a_labl['accuracy'].mean(), \n",
    "                             'precision':df_a_labl['precision'].mean(),\n",
    "                             'recall':df_a_labl['recall'].mean(),\n",
    "                             'ROC':df_a_labl['roc_auc'].mean(), 'f1_score':df_a_labl['f1_score'].mean()}\n",
    "\n",
    "    if print_results:\n",
    "        print(f'\\n  ==================  Total  ==================\\n\\n\\n')\n",
    "        print(f\"Mean accuracy: {df['accuracy'].mean()}({df['accuracy'].std()})\")\n",
    "        print(f\"Mean ROC: {df['roc_auc'].mean()} ({df['roc_auc'].std()})\")\n",
    "        print(f\"Mean f1_score: {df['f1_score'].mean()}({df['f1_score'].std()})\")\n",
    "        print(f\"Mean precision: {df['precision'].mean()}({df['precision'].std()})\")\n",
    "        print(f\"Mean recall: {df['recall'].mean()}({df['recall'].std()})\\n\")\n",
    "    \n",
    "    dic_results['total'] = {'accuracy':df['accuracy'].mean(), \n",
    "                             'precision':df['precision'].mean(),\n",
    "                             'recall':df['recall'].mean(),\n",
    "                             'ROC':df['roc_auc'].mean(), 'f1_score':df['f1_score'].mean()}\n",
    "    return dic_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(X, y):\n",
    "    \n",
    "    print(f\"Before balancing, counts of label '1': {sum(y == 1)}\")\n",
    "    print(f\"Before balancing, counts of label '0': {sum(y == 0)}\\n\")\n",
    "\n",
    "    saved_cols = X.columns\n",
    "    sm = SMOTE(random_state=42)\n",
    "        \n",
    "    X_res, y_res = sm.fit_sample(X.copy(), y.copy().ravel())\n",
    "    \n",
    "    print(f\"After balancing, counts of label '1': {sum(y_res == 1)}\")\n",
    "    print(f\"After balancing, counts of label '0': {sum(y_res == 0)}\")\n",
    "\n",
    "    return pd.DataFrame(X_res, columns=saved_cols), pd.Series(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def classification(df, selected_type, run , n=5, SCALE_POS_RATIO=\"ratio\",\n",
    "                   early_stopping=10, learning_rate=0.3, depth=6, threshold=0.5,\n",
    "                   G=0, subsample_ratio=1, alpha=0, obj='reg:squarederror', PR = True):\n",
    "    \"\"\"\n",
    "    This function creates the machine learning model \n",
    "    \n",
    "    Args: \n",
    "        df: A DataFrame of drug-target interactions (train and internal-test 90%)\n",
    "        selected_type: list of labels\n",
    "        n: Number of folds\n",
    "        SCALE_POS_RATIO: ratio for imbalnace dataset (\"ratio\": num_0/num_1/\"SMOTE\": balance trainset/ 'None':real data/int: give a number --for tuning)\n",
    "        early_stopping: early_stopping\n",
    "        learning_rate: learning_rate --> [0,1]\n",
    "        depth: Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit\n",
    "        G: gamma\n",
    "        subsample_ratio: Subsample ratio of the training instances\n",
    "        PR: print results (True for multi-calss)\n",
    "    Returns: \n",
    "        all_train_results: Traning results for n folds\n",
    "        all_test_results: Testing results for n folds\n",
    "        dic_results_train: dic train summary result\n",
    "        dic_results_test: dic test summary result\n",
    "    \"\"\"\n",
    "    \n",
    "    num_crossVal = 0 \n",
    "    all_train_results, all_test_results = [], []\n",
    "    kf = KFold(n_splits=n, random_state=42, shuffle=True)\n",
    "\n",
    "    DTI_for_ML = df.copy()\n",
    "    kf.get_n_splits(DTI_for_ML)\n",
    "\n",
    "    for train_index, test_index in kf.split(DTI_for_ML):\n",
    "        df_train, df_test = DTI_for_ML.iloc[train_index], DTI_for_ML.iloc[test_index]\n",
    "        num_crossVal = num_crossVal + 1 \n",
    "        print(f'\\n\\n\\n  KFold: {num_crossVal}')\n",
    "        print(f'# all DTI: {DTI_for_ML.shape[0]}')\n",
    "        print(f'# DTI train-set: {df_train.shape[0]}')\n",
    "        print(f'# DTI test-set: {df_test.shape[0]}')\n",
    "\n",
    "        for label in selected_type:\n",
    "            print('\\n\\n=============================================================')\n",
    "            print(f'training for {label}...')\n",
    "            X, y = get_data(df_train, label, selected_type)\n",
    "            print(f'X_train.shape: {X.shape}')\n",
    "            \n",
    "            print(f'testing for {label}...')\n",
    "            X_test, y_test = get_data(df_test, label, selected_type)\n",
    "            print(f'X_test.shape: {X_test.shape}')\n",
    "\n",
    "            if SCALE_POS_RATIO == 'ratio':\n",
    "                weight_ratio = get_sample_weight(y)\n",
    "                model = XGBClassifier(scale_pos_weight=weight_ratio, eta=learning_rate, max_depth= depth,\n",
    "                                      gamma= G, subsample=subsample_ratio, reg_alpha=alpha, objective=obj)\n",
    "                \n",
    "            elif SCALE_POS_RATIO == 'SMOTE':\n",
    "                model = XGBClassifier(eta=learning_rate, max_depth= depth, gamma= G, subsample=subsample_ratio, \n",
    "                                      reg_alpha=alpha, objective=obj)\n",
    "                X, y = balance_df(X, y)\n",
    "            \n",
    "            elif SCALE_POS_RATIO == 'None':\n",
    "                model = XGBClassifier(eta=learning_rate, max_depth= depth, gamma= G, subsample=subsample_ratio,\n",
    "                                     reg_alpha=alpha, objective=obj)\n",
    "                \n",
    "            else:\n",
    "                model = XGBClassifier(scale_pos_weight=SCALE_POS_RATIO, eta=learning_rate, max_depth= depth,\n",
    "                                      gamma= G, subsample=subsample_ratio, reg_alpha=alpha, objective=obj)\n",
    "            \n",
    "            model.fit(X, y, early_stopping_rounds=early_stopping, eval_metric=['logloss', 'auc'], eval_set=[(X_test, y_test)], verbose=True)\n",
    "            #PCA_label (X, y)\n",
    "            #print(f'Label: {label}\\n\\n')\n",
    "\n",
    "            # predic probability\n",
    "            pred_train_proba = model.predict_proba(X)[:,1]\n",
    "            # map to binary\n",
    "            pred_train = list(np.where(pred_train_proba> threshold, 1, 0))\n",
    "            \n",
    "            train_results = calculate_metrics(y, pred_train)\n",
    "            train_results['clf_name'] = label\n",
    "            train_results['model'] = model\n",
    "            train_results['Kfold'] = num_crossVal\n",
    "            train_results['Run'] = run+1\n",
    "\n",
    "            all_train_results.append(train_results)\n",
    "           \n",
    "            \n",
    "            # predic probability\n",
    "            pred_test_proba = model.predict_proba(X_test)[:,1]\n",
    "            # map to binary\n",
    "            pred_test = list(np.where(pred_test_proba>threshold, 1, 0))\n",
    "            \n",
    "            test_results = calculate_metrics(y_test, pred_test)\n",
    "            test_results['clf_name'] = label\n",
    "            test_results['model'] = model\n",
    "            test_results['Kfold'] = num_crossVal\n",
    "            test_results['Run'] = run+1\n",
    "            all_test_results.append(test_results)\n",
    "            print(f'test_results: {test_results}')\n",
    "            \n",
    "    df_all_test_results = pd.DataFrame(all_test_results)\n",
    "    df_all_train_results = pd.DataFrame(all_train_results)  \n",
    "    \n",
    "    \n",
    "        \n",
    "    print('train summary results')\n",
    "    dic_results_train = summary_results(df_all_train_results, print_results=PR)\n",
    "\n",
    "    print('internal-test summary results')\n",
    "    dic_results_test = summary_results(df_all_test_results, print_results=PR)\n",
    "    \n",
    "    return all_train_results, all_test_results, dic_results_train, dic_results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5 \n",
    "RUN = 5\n",
    "FOLD = 5\n",
    "LEARNING_RATE = 0.01\n",
    "BALANCING = 'SMOTE' #['None','SMOTE','ratio',int],\n",
    "STOPPING = 20\n",
    "DEPTH = 5\n",
    "GAMMA = 1\n",
    "SUBSAMPLE = 1\n",
    "ALPHA = 0\n",
    "OBJECTIVE ='reg:squarederror'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "resuts_all_runs_test = []\n",
    "resuts_all_runs_train = []\n",
    "resuts_external_list = []\n",
    "\n",
    "for run in range(0, RUN):\n",
    "    # 10% as external test set, 90% internal-test and train\n",
    "    DTI_external_test = df_interaction_newLabel.sample(frac = 0.1)\n",
    "    DTI_new = df_interaction_newLabel.drop(DTI_external_test.index)\n",
    "\n",
    "    all_train_results, all_test_results, dic_results_train, dic_results_test = classification (DTI_new, selected_type, run=RUN, n=FOLD, SCALE_POS_RATIO=BALANCING, \n",
    "                                                                                               early_stopping=STOPPING, learning_rate=LEARNING_RATE, depth=DEPTH,\n",
    "                                                                                               threshold=THRESHOLD, G=GAMMA, subsample_ratio= SUBSAMPLE, alpha=ALPHA,\n",
    "                                                                                              obj=OBJECTIVE, PR=True )                                                                                                                                                                                                                                                                               \n",
    "\n",
    "    # find the best model on internal testset and apply on external testset\n",
    "    for i in selected_type:\n",
    "        df_test_all = pd.DataFrame(all_test_results)\n",
    "        best_model_for_a_label = list(df_test_all[df_test_all['clf_name']==i].sort_values(by=['f1_score'], ascending=False)['model'])[0]\n",
    "\n",
    "        X_ex, y_ex = get_data(DTI_external_test, i, selected_type)\n",
    "        ## hello\n",
    "        X_ex, y_ex = balance_df(X_ex, y_ex)\n",
    "        ## hello\n",
    "        pred_extest_proba = best_model_for_a_label.predict_proba(X_ex)[:,1]\n",
    "        pred_extest = list(np.where(pred_extest_proba>THRESHOLD, 1, 0))\n",
    "\n",
    "        extest_results = calculate_metrics(y_ex, pred_extest)\n",
    "        extest_results['Run'] = run+1\n",
    "        extest_results['clf_name'] = i\n",
    "        extest_results['best_model'] = best_model_for_a_label\n",
    "\n",
    "        resuts_external_list.append(extest_results)\n",
    "        \n",
    "    resuts_all_runs_test = resuts_all_runs_test + all_test_results\n",
    "    resuts_all_runs_train = resuts_all_runs_train + all_train_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### External-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_ex_results = pd.DataFrame(resuts_external_list)\n",
    "dic_ex_results = summary_results(df_ex_results, print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internal-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_of_test = summary_results(pd.DataFrame(all_test_results), print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary_of_train = summary_results(pd.DataFrame(all_train_results), print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report\n",
    "for i in selected_type:\n",
    "    n_label = df_interaction_newLabel[i].sum()\n",
    "    n_rest = len(df_interaction_newLabel)- n_label\n",
    "    print (f'number of {i}: {n_label} VS. rest: {n_rest}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unkown drug-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_unknown_drug(set_all_drug, set_all_target, dic_all_interactions):\n",
    "    \"\"\"\n",
    "    This function create all unkown drug-target interactions and save it (.pkl)\n",
    "    \n",
    "    Args: \n",
    "        set_all_drug: list of unique drug names\n",
    "        set_all_target: list of unique target names\n",
    "        dic_all_interactions: dictionary of all known drug-target interactions    \n",
    "    \"\"\"\n",
    "    \n",
    "    first = 0\n",
    "    step = 50000\n",
    "    len_total = 0 \n",
    "    # Sinece the data is big --> spilit it to small parts and save them separately\n",
    "    for i in range(step, len(set_all_drug), step):\n",
    "        set_all_drug_temp = set_all_drug[first:i]\n",
    "        all_unknown_interactions = {(x,y) for x in set_all_drug_temp for y in set_all_target}\n",
    "        all_unknown_interactions.difference_update(dic_all_interactions.keys())\n",
    "        with open(f'unknown_interactions_'+f'{first}_{i}.pkl', 'wb') as fp:\n",
    "            pickle.dump(all_unknown_interactions, fp)\n",
    "        print(f'\\nindex: {first}_{i}')\n",
    "        print(f'len: {len(all_unknown_interactions)}')\n",
    "        first = i \n",
    "        len_total += len(all_unknown_interactions)\n",
    "        del all_unknown_interactions \n",
    "        del set_all_drug_temp\n",
    "\n",
    "    if first < len(set_all_drug):\n",
    "        set_all_drug_temp = set_all_drug[first:len(set_all_drug)]\n",
    "        all_unknown_interactions = {(x,y) for x in set_all_drug_temp for y in set_all_target}\n",
    "        all_unknown_interactions.difference_update(dic_all_interactions.keys())\n",
    "        with open(f'unknown_interactions_'+ f'{first}_{len(set_all_drug)}.pkl', 'wb') as fp:\n",
    "            pickle.dump(all_unknown_interactions, fp)\n",
    "        print(f'\\nindex: {first}_{len(set_all_drug)}')\n",
    "        print(f'len: {len(all_unknown_interactions)}')\n",
    "        len_total += len(all_unknown_interactions)\n",
    "        del all_unknown_interactions \n",
    "        del set_all_drug_temp\n",
    "   \n",
    "    del dic_all_interactions ## delete**: have a df of dic_all_interactions --> df_all_DTI\n",
    "    print(f'\\nlen unkown DTI: {len_total}')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unknown_interactions_0_276.pkl', 'rb') as f:\n",
    "    unknown_interactions = pickle.load(f)\n",
    "df_unknown_DTI = pd.DataFrame(unknown_interactions, columns= ['from','to'])\n",
    "df_unknown_DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting interaction (remove noises)\n",
    "new_DTI_tmp = new_DTI.reset_index().drop(columns= ['index'])\n",
    "new_DTI_tmp = pd.concat([new_DTI_tmp,df_label], axis=1)\n",
    "\n",
    "all_known_int = new_DTI_tmp[new_DTI_tmp.index.isin(df_interaction_newLabel.index)]\n",
    "set_all_target = list(set(all_known_int['to']))\n",
    "set_all_drug = list(set(all_known_int['from']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_known_int['tuple_of_int'] = all_known_int[['from', 'to']].apply(tuple, axis=1)\n",
    "dic_all_interactions = pd.Series(all_known_int['decreases^activity'].values, index=all_known_int['tuple_of_int']).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = all_known_int[all_known_int['decreases^reaction']==1]\n",
    "sample1['from']= sample1['from'].map(numId2drugId).apply(lambda x: f\"CHEMBL{x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in selected_type:\n",
    "    n_label = df_interaction_newLabel[i].sum()\n",
    "    n_rest = len(df_interaction_newLabel)- n_label\n",
    "    print (f'number of {i}: {n_label} VS. rest: {n_rest}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unknown_drug(set_all_drug, set_all_target, dic_all_interactions)\n",
    "print(f'Number of target: {len(set_all_target)}')\n",
    "print(f'Number of drug: {len(set_all_drug)}')\n",
    "print(f'Number of DTI: {len(all_known_int)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## All interactions\n",
    "with open('all_nod2vec_new.pkl', 'rb') as f:\n",
    "    all_nod2vec_new = pickle.load(f)\n",
    "\n",
    "with open('diseaseId2numId_nod2vec.pkl', 'rb') as f:\n",
    "    disId2numId = pickle.load(f)\n",
    "numId2dis = pd.Series(disId2numId.keys(), index=disId2numId.values()).to_dict()\n",
    "\n",
    "with open('disid2disname.pkl', 'rb') as f:\n",
    "    disid2disname = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diseas without drug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_disease = set(list(all_nod2vec_new[all_nod2vec_new['Type_Interaction']=='DisD']['to'])+list(all_nod2vec_new[all_nod2vec_new['Type_Interaction']=='DisT']['from']))\n",
    "\n",
    "DisD_interactions = all_nod2vec_new[all_nod2vec_new['Type_Interaction']=='DisD']\n",
    "dis_with_dug = set(DisD_interactions['to'])\n",
    "dis_without_drug = all_disease - dis_with_dug\n",
    "\n",
    "print(f'number of  all disease : {len(all_disease)}')\n",
    "print(f'number of disease without drug: {len(dis_without_drug)}')\n",
    "print(f'number of disease with drug: {len(dis_with_dug)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('name of diseases without known drug: \\n')\n",
    "name_diseses_without_drug = list(pd.DataFrame(dis_without_drug)[0].map(numId2dis).map(disid2disname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## target for the diseases without drug\n",
    "DisT_interactions = all_nod2vec_new[all_nod2vec_new['Type_Interaction']=='DisT']\n",
    "DisT_for_diseases_without_drug = DisT_interactions[DisT_interactions['from'].isin(list(dis_without_drug))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dis embediing vectors\n",
    "embeddings_dis = embeddings_all[embeddings_all.index.isin(all_disease)]\n",
    "embeddings_dis.index = embeddings_dis.index.map(numId2dis) #.map(disid2disname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(\n",
    "    n_clusters=5, init='random',\n",
    "    n_init=10, max_iter=300, \n",
    "    tol=1e-04, random_state=0)\n",
    "\n",
    "y_km = km.fit_predict(embeddings_dis)\n",
    "\n",
    "embeddings_dis_km = embeddings_dis.copy()\n",
    "embeddings_dis_km['km'] = y_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disese name and cluster\n",
    "dises_cluster = embeddings_dis[[1]]\n",
    "dises_cluster['cluster'] = y_km\n",
    "dises_cluster['dis'] = dises_cluster.index\n",
    "dises_cluster = dises_cluster[['cluster', 'dis']]\n",
    "dises_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PCA_label(embeddings_dis, y_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disname2disid = pd.Series(disid2disname.keys(), index =disid2disname.values()).to_dict()\n",
    "dis2numId = pd.Series(numId2dis.keys(), index =numId2dis.values()).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing model for expeimental data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_POS_RATIO=BALANCING\n",
    "early_stopping=STOPPING\n",
    "learning_rate=LEARNING_RATE\n",
    "depth=DEPTH\n",
    "threshold=THRESHOLD\n",
    "G=GAMMA\n",
    "subsample_ratio= SUBSAMPLE\n",
    "alpha=ALPHA\n",
    "obj=OBJECTIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step for new DTI prediction --> predict positive or negative\n",
    "df_final_tmp = df_final.iloc[:,:-1]\n",
    "df_final_tmp['type_int'] = 1\n",
    "\n",
    "# negative interactions\n",
    "df_negative_final_tmp = df_negative_final.iloc[:, :-1]\n",
    "df_negative_final_tmp['type_int'] = 0\n",
    "df_poditive_negative_DTI = df_final_tmp.append(df_negative_final_tmp).reset_index(drop=True)\n",
    "\n",
    "df_poditive_negative_DTI['type_int'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poditive_negative_DTI1 = df_poditive_negative_DTI.copy()\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(df_poditive_negative_DTI.drop(columns= ['type_int']).dropna().values)\n",
    "\n",
    "\n",
    "df_poditive_negative_DTI1['PCA-1'] = pca_result[:,0]\n",
    "df_poditive_negative_DTI1['PCA-2'] = pca_result[:,1]\n",
    "df_poditive_negative_DTI1['PCA-3'] = pca_result[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poditive_negative_DTI1['type_int'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "x = df_poditive_negative_DTI1['PCA-1']\n",
    "y = df_poditive_negative_DTI1['PCA-2']\n",
    "z = df_poditive_negative_DTI1['PCA-3']\n",
    "\n",
    "cmap_dict = {0: \"red\", 1: \"green\"}\n",
    "cmap = ListedColormap(list(cmap_dict.values()))\n",
    "\n",
    "ax.set_xlabel(\" \")\n",
    "ax.set_ylabel(\" \")\n",
    "ax.set_zlabel(\" \")\n",
    "\n",
    "sc = ax.scatter(x, y, z, s=30,cmap=cmap, c=df_poditive_negative_DTI['type_int'], marker='o', alpha=1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_label(df_poditive_negative_DTI.drop(columns= ['type_int']),df_poditive_negative_DTI['type_int'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT2Vec(df_poditive_negative_DTI, SCALE_POS_RATIO=BALANCING, early_stopping=STOPPING,\n",
    "           learning_rate=LEARNING_RATE, depth=DEPTH, threshold=THRESHOLD, G=GAMMA, subsample_ratio= SUBSAMPLE,\n",
    "           alpha=ALPHA, obj=OBJECTIVE, mode_test=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is DT2Vec method, used for predincting positive and negative interactions\n",
    "    \n",
    "    Args: \n",
    "        df_poditive_negative_DTI: df of embedded vectors of postive and negative interactions\n",
    "        SCALE_POS_RATIO: ratio for imbalnace dataset (\"ratio\": num_0/num_1/\"SMOTE\": balance trainset/ 'None':real data/int: give a number --for tuning)\n",
    "        early_stopping: early_stopping\n",
    "        learning_rate: learning_rate --> [0,1]\n",
    "        depth: Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit\n",
    "        G: gamma\n",
    "        subsample_ratio: Subsample ratio of the training instances\n",
    "        mode_test: True for evalutaing method (test, train, validation), False for developing method (train and test)  \n",
    "    \"\"\"\n",
    "    \n",
    "    # XGBoost\n",
    "    resuts_all_runs_test = []\n",
    "    resuts_all_runs_train = []\n",
    "    resuts_external_list = []\n",
    "    selected_type = ['type_int']\n",
    "    \n",
    "    for run in range(0, RUN):\n",
    "        if mode_test:\n",
    "            # 10% as external test set, 90% internal-test and train\n",
    "            DTI_external_test = df_poditive_negative_DTI.sample(frac = 0.1)\n",
    "            DTI_new = df_poditive_negative_DTI.drop(DTI_external_test.index)\n",
    "        else:\n",
    "            DTI_new = df_poditive_negative_DTI.copy()\n",
    "\n",
    "        all_train_results, all_test_results, dic_results_train, dic_results_test = classification (DTI_new, selected_type, run=RUN, n=FOLD, SCALE_POS_RATIO=BALANCING, \n",
    "                                                                                                   early_stopping=STOPPING, learning_rate=LEARNING_RATE, depth=DEPTH,\n",
    "                                                                                                   threshold=THRESHOLD, G=GAMMA, subsample_ratio= SUBSAMPLE, alpha=ALPHA,\n",
    "                                                                                                  obj=OBJECTIVE, PR=False)                                                                                                                                                                                                                                                                               \n",
    "\n",
    "        # find the best model on internal testset and apply on external testset\n",
    "        if mode_test:\n",
    "            for i in selected_type:\n",
    "                df_test_all = pd.DataFrame(all_test_results)\n",
    "                best_model_for_a_label = list(df_test_all[df_test_all['clf_name']==i].sort_values(by=['f1_score'], ascending=False)['model'])[0]\n",
    "\n",
    "                X_ex, y_ex = get_data(DTI_external_test, i, selected_type)\n",
    "                 ## hello\n",
    "                X_ex, y_ex = balance_df(X_ex, y_ex)\n",
    "                ## hello\n",
    "                pred_extest_proba = best_model_for_a_label.predict_proba(X_ex)[:,1]\n",
    "                pred_extest = list(np.where(pred_extest_proba>THRESHOLD, 1, 0))\n",
    "\n",
    "                extest_results = calculate_metrics(y_ex, pred_extest)\n",
    "                extest_results['Run'] = run+1\n",
    "                extest_results['clf_name'] = i\n",
    "                extest_results['best_model'] = best_model_for_a_label\n",
    "\n",
    "                resuts_external_list.append(extest_results)\n",
    "\n",
    "        resuts_all_runs_test = resuts_all_runs_test + all_test_results\n",
    "        resuts_all_runs_train = resuts_all_runs_train + all_train_results\n",
    "    \n",
    "    return pd.DataFrame(resuts_all_runs_test), pd.DataFrame(resuts_all_runs_train), pd.DataFrame(resuts_external_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poditive_negative_DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing the method by having test, train and external test\n",
    "#df_poditive_negative_DTI = df_poditive_negative_DTI.drop(columns= ['PCA-1','PCA-2','PCA-3'])\n",
    "resuts_all_runs_tPN_test, resuts_all_runs_train_tPN, resuts_external_list_tPN = DT2Vec(df_poditive_negative_DTI, mode_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resuts_external_list_tPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resuts_external_list_tPN['accuracy'].mean())\n",
    "print(resuts_external_list_tPN['accuracy'].std())\n",
    "print(resuts_external_list_tPN['f1_score'].mean())\n",
    "print(resuts_external_list_tPN['f1_score'].std())\n",
    "print(resuts_external_list_tPN['precision'].mean())\n",
    "print(resuts_external_list_tPN['precision'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# developing model for predicting positive and negative interactions\n",
    "dic_model = {}\n",
    "\n",
    "resuts_all_runs_test_PN, resuts_all_runs_train_PN, resuts_external_list_PN = DT2Vec(df_poditive_negative_DTI)\n",
    "\n",
    "# selecte best model with highest f1_score\n",
    "best_PN_model = resuts_all_runs_test_PN.sort_values(by=['f1_score'], ascending=False)['model'][0]\n",
    "dic_model['postive/negative'] = best_PN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XGBoost \n",
    "resuts_all_runs_test_final = []\n",
    "resuts_all_runs_train_final = []\n",
    "\n",
    "for run in range(0, RUN):\n",
    "    # 10% as external test set, 90% internal-test and train\n",
    "    DTI_new_final = df_interaction_newLabel.copy()\n",
    "\n",
    "    all_train_results_final, all_test_results_final, dic_results_train_final, dic_results_test_final = classification (DTI_new_final, selected_type, run=RUN, n=FOLD, SCALE_POS_RATIO=BALANCING, \n",
    "                                                                                               early_stopping=STOPPING, learning_rate=LEARNING_RATE, depth=DEPTH,\n",
    "                                                                                               threshold=THRESHOLD, G=GAMMA, subsample_ratio= SUBSAMPLE, alpha=ALPHA,\n",
    "                                                                                              obj=OBJECTIVE)                                                                                                                                                                                                                                                                               \n",
    "    resuts_all_runs_test_final = resuts_all_runs_test_final + all_train_results_final\n",
    "    resuts_all_runs_train_final = resuts_all_runs_train_final + all_test_results_final\n",
    "    \n",
    "# find the best model \n",
    "for i in selected_type:\n",
    "    df_test_all_final = pd.DataFrame(resuts_all_runs_test_final)\n",
    "    best_model_for_a_label_final = list(df_test_all_final[df_test_all_final['clf_name']==i].sort_values(by=['f1_score'], ascending=False)['model'])[0]\n",
    "\n",
    "    dic_model[i] = best_model_for_a_label_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on unkown DTIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unkown drug-target\n",
    "df_unknown_DTI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIRC5\n",
    "df_unknown_DTI[df_unknown_DTI['to']==332]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vector_unknown_DTI.pkl', 'rb') as f:\n",
    "    vector_unknown_DTI = pickle.load(f)\n",
    "vector_unknown_DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prdict P/N interactation labels for unkown DTIs\n",
    "pred_proba_PosNeg = dic_model['postive/negative'].predict_proba(vector_unknown_DTI)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding Pos/Neg labels and drug/target names\n",
    "vector_unknown_DTI_label = vector_unknown_DTI.copy()\n",
    "vector_unknown_DTI_label['Pos/Neg'] = pred_proba_PosNeg\n",
    "vector_unknown_DTI_label['from'] = df_unknown_DTI['from']\n",
    "vector_unknown_DTI_label['to'] = df_unknown_DTI['to']\n",
    "vector_unknown_DTI_label = vector_unknown_DTI_label.sort_values(by=['Pos/Neg'], ascending=False)\n",
    "vector_unknown_DTI_label                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select highy positive interactions \n",
    "highy_pos_DTI = vector_unknown_DTI_label[vector_unknown_DTI_label['Pos/Neg']>=0.95]\n",
    "highy_pos_DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highy_pos_DTI[highy_pos_DTI['to']== 7157]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unkown_DTI_labels = highy_pos_DTI.copy()\n",
    "for i in selected_type:\n",
    "    new_label = dic_model[i].predict_proba(highy_pos_DTI.drop(columns=['Pos/Neg','from','to']))[:,1]\n",
    "    unkown_DTI_labels[i] = new_label\n",
    "unkown_DTI_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# selecting 110 dtis in each labels\n",
    "dic_new_DTIs = {}\n",
    "unkown_DTI_labels['from_to_tuples'] = list(unkown_DTI_labels[['from', 'to']].to_records(index=False))\n",
    "\n",
    "for i in selected_type:\n",
    "    dic_new_DTIs[i] = unkown_DTI_labels.sort_values(by=[i], ascending=False)[['from','to','Pos/Neg','from_to_tuples',i]][:110]\n",
    "dic_new_DTIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Wege interactions : increases^expression and'decreases^expression' or 'decreases^reaction', 'increases^reaction' or 'increases^activity', 'decreases^activity'\n",
    "expression_dub = [name for name in list(dic_new_DTIs['increases^expression']['from_to_tuples']) if name in list(dic_new_DTIs['decreases^expression']['from_to_tuples']) ]\n",
    "reaction_dub = [name for name in list(dic_new_DTIs['increases^reaction']['from_to_tuples']) if name in list(dic_new_DTIs['decreases^reaction']['from_to_tuples']) ]\n",
    "activity_dub = [name for name in list(dic_new_DTIs['increases^activity']['from_to_tuples']) if name in list(dic_new_DTIs['decreases^activity']['from_to_tuples']) ]\n",
    "activity_dub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_new_DTIs['increases^activity'] = dic_new_DTIs['increases^activity'][~dic_new_DTIs['increases^activity']['from_to_tuples'].isin(activity_dub)][:100]\n",
    "dic_new_DTIs['decreases^activity'] = dic_new_DTIs['decreases^activity'][~dic_new_DTIs['decreases^activity']['from_to_tuples'].isin(activity_dub)][:100]\n",
    "\n",
    "dic_new_DTIs['increases^activity'] = dic_new_DTIs['increases^activity'][:100]\n",
    "dic_new_DTIs['decreases^activity'] = dic_new_DTIs['decreases^activity'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_new_DTIs_new  = dic_new_DTIs.copy()\n",
    "for i in selected_type:\n",
    "    dic_new_DTIs[i]['ChEMBL id'] = dic_new_DTIs[i]['from'].map(numId2drugId).apply(lambda x: f\"CHEMBL{x}\")\n",
    "    dic_new_DTIs[i]['Entrez Gene id']= dic_new_DTIs[i]['to'].map(entrezgene_dic)\n",
    "    j = i.replace('^', '_')\n",
    "    dic_new_DTIs[i].to_csv(f'DTI2VecPLUS/{j}.csv')\n",
    "dic_new_DTIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_decreases_expression = dic_new_DTIs['decreases^expression']\n",
    "new_decreases_expression['drug_id'] = new_decreases_expression['ChEMBL id'].map(chmble2drugname)\n",
    "new_decreases_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibpart_plot = pd.DataFrame({'from':[0],'to':[0], 'Pos/Neg':[0], 'from_to_tuples':[0],\n",
    "              'ChEMBL id':[0], 'Entrez Gene id':[0], 'drug_id':[0], 'type_interaction':[0]})\n",
    "for i in selected_type:\n",
    "    tmp = dic_new_DTIs[i][['from','to','Pos/Neg','from_to_tuples','ChEMBL id','Entrez Gene id']][:20]\n",
    "    tmp['drug_id'] = tmp['ChEMBL id'].map(chmble2drugname)\n",
    "    tmp['type_interaction'] = i\n",
    "    bibpart_plot = bibpart_plot.append(tmp)\n",
    "bibpart_plot = bibpart_plot[1:]\n",
    "bibpart_plot['bi-1']= 1\n",
    "bibpart_plot['bi-0']= 0\n",
    "bibpart_plot = bibpart_plot.sort_values(by= 'drug_id')\n",
    "bibpart_plot['main']=bibpart_plot['drug_id']+bibpart_plot['Entrez Gene id'] \n",
    "bibpart_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(bibpart_plot['drug_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibpart_plot[['drug_id','Entrez Gene id','bi-1','bi-0']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {'decreases^activity':'#5C5D9E',\n",
    " 'decreases^expression':'#317EC2',\n",
    " 'decreases^reaction':'#5AAA46',\n",
    " 'increases^activity':'#C03830',\n",
    " 'increases^expression':'#E7872B',\n",
    " 'increases^reaction':'#E9C61D'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bibpart_plot['color']= bibpart_plot['type_interaction'].map(color_dict)\n",
    "color_dict_final = pd.Series(bibpart_plot['color'].values, index=bibpart_plot['main'] ).to_dict()\n",
    "color_dict_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibpart_plot[['drug_id','Entrez Gene id', 'color']].to_csv('chart.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disease without drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drug_reperpusing_dis(embeddings_all, df_unknown_DTI, numId2drugId, drug_cut2chem, dic_model,\n",
    "                         target_gene, pre_list, TH):\n",
    "    \"\"\"\n",
    "    This function use for drug repupusing\n",
    "    \n",
    "    Args: \n",
    "        embeddings_all: Data frame of embedding vectors\n",
    "        df_unknown_DTI: Data frame of unkown DTI\n",
    "        numId2drugId: dict of id to drug ids\n",
    "        drug_cut2chem: dict of drug ids\n",
    "        dic_model: dictinary of models\n",
    "        target_gene: a target gene\n",
    "        pre_list: type of interactions\n",
    "        TH: Thereashod of probability\n",
    "        \n",
    "    Return:  Dictianary of new dug and it probability\n",
    "        \n",
    "        \"\"\"\n",
    "    dic_new_dug = {}\n",
    "    selected_gene = df_unknown_DTI[df_unknown_DTI['to']==target_gene]\n",
    "    df_vector_interactions = concating(selected_gene, embeddings_all)\n",
    "\n",
    "    # finding positive interactions using DT2Vec\n",
    "    pred_proba_PN = dic_model['postive/negative'].predict_proba(df_vector_interactions)[:,1]\n",
    "    pred_PN = list(np.where(pred_proba_PN>=TH, 1, 0))\n",
    "\n",
    "    df_all = pd.concat([df_vector_interactions, selected_gene.reset_index(drop=True)], axis=1)\n",
    "    df_all['drug'] = df_all['from'].map(numId2drugId).map(drug_cut2chem)\n",
    "\n",
    "    df_all['label_proba_PN'] = pred_proba_PN\n",
    "    df_all['label_PN'] = pred_PN\n",
    "\n",
    "    for i in pre_list:\n",
    "        pred_proba_a_label = dic_model[i].predict_proba(df_vector_interactions)[:,1]\n",
    "        df_all[f'{i}_proba'] = pred_proba_a_label    \n",
    "        pred_a_label = list(np.where(pred_proba_a_label>=TH, 1, 0))\n",
    "        df_all[i] = pred_a_label\n",
    "\n",
    "\n",
    "        # tuple of drug and predicted probability \n",
    "        df_all[f'drug_proba_{i}'] = df_all[['drug', f'{i}_proba']].apply(tuple, axis=1)\n",
    "\n",
    "        # positive intearctions\n",
    "        df_all_p = df_all[df_all['label_PN']==1]\n",
    "\n",
    "        dic_new_dug[i] = list(df_all_p[df_all_p[i]==1][f'drug_proba_{i}'])\n",
    "    return dic_new_dug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COVID-19 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of gene for covid not available in the graph\n",
    "AllDisGene[(AllDisGene['MESH:D000014']=='MESH:D000086382') & (AllDisGene['Unnamed: 4']=='marker/mechanism')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Covid clusters\n",
    "cluster_4 = embeddings_dis_km[embeddings_dis_km['km']==4].sort_values(by=[0])\n",
    "cluster_4['dis']= cluster_4.index.map(disid2disname)\n",
    "list(cluster_4['dis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID_19 = DisT_for_diseases_without_drug[DisT_for_diseases_without_drug['from']==100506959]\n",
    "COVID_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drugs that can bind to covid's genes\n",
    "covid_genes = COVID_19['to']\n",
    "DTI_covid_genes = all_known_int[all_known_int['to'].isin(covid_genes)]\n",
    "DTI_covid_genes['from'] = DTI_covid_genes['from'].map(numId2drugId).map(drug_cut2chem)\n",
    "DTI_covid_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugId2numId_nod2vec[41286]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drug id name based on Chmble id \n",
    "numId2drugId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACE2\n",
    "- Finding new drugs that can bind to this genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTI[DTI['to']==59272]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_gene = 59272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_59272 = {}\n",
    "df_all_59272 = pd.DataFrame(data={'from': [0], 'to': [0], 'type':[0], 'pro':[0]})\n",
    "repurpusing_59272_new = unkown_DTI_labels[unkown_DTI_labels['to']==target_gene] \n",
    "repurpusing_59272_new['from'] = repurpusing_59272_new['from'].map(numId2drugId).apply(lambda x: f\"CHEMBL{x}\")\n",
    "for i in ['increases^activity', 'increases^expression', 'increases^reaction']:\n",
    "    dic_59272[i] = repurpusing_59272_new[repurpusing_59272_new [i]>=0.5].sort_values(by=[i], ascending=False)\n",
    "    print(dic_59272[i][['Pos/Neg','from','to',i]].head(5))\n",
    "    print('')\n",
    "    df_all_59272_tmp = dic_59272[i][['from','to']]\n",
    "    df_all_59272_tmp['type'] = i\n",
    "    df_all_59272_tmp['pro'] = dic_59272[i][i]\n",
    "    df_all_59272 = df_all_59272.append(df_all_59272_tmp)\n",
    "df_all_59272 = df_all_59272[1:].sort_values(by=['pro'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# top 50 drug for\n",
    "df_all_59272.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BSG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_gene = 682\n",
    "pre_list = ['decreases^activity', 'decreases^expression', 'decreases^reaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_682 = {}\n",
    "df_all_682 = pd.DataFrame(data={'from': [0], 'to': [0], 'type':[0], 'pro':[0]})\n",
    "repurpusing_682_new = unkown_DTI_labels[unkown_DTI_labels['to']==target_gene] \n",
    "repurpusing_682_new['from'] = repurpusing_682_new['from'].map(numId2drugId).apply(lambda x: f\"CHEMBL{x}\")\n",
    "for i in pre_list:\n",
    "    dic_682[i] = repurpusing_682_new[repurpusing_682_new [i]>=0.5].sort_values(by=[i], ascending=False)\n",
    "    print(dic_682[i][['Pos/Neg','from','to',i]].head(5))\n",
    "    print('')\n",
    "    df_all_682_tmp = dic_682[i][['from','to']]\n",
    "    df_all_682_tmp['type'] = i\n",
    "    df_all_682_tmp['pro'] = dic_682[i][i]\n",
    "    df_all_682 = df_all_682.append(df_all_682_tmp)\n",
    "df_all_682 = df_all_682[1:].sort_values(by=['pro'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all_682.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dds_newdrug (kownDrug=[100506944,100506799], num=100):\n",
    "    newDrugList = list(df_all_682.head(num)['from'].str.replace('CHEMBL', '').astype(int).map(drugId2numId_nod2vec))\n",
    "    unknow_known_DDS = allDDS[(allDDS['from'].isin(kownDrug)|allDDS['to'].isin(kownDrug)) & (allDDS['to'].isin(newDrugList)|allDDS['from'].isin(newDrugList))].sort_values(by=['weight'], ascending=False)\n",
    "    unknow_known_DDS['from_id'] = unknow_known_DDS['from'].map(numId2drugId).apply(lambda x: f\"CHEMBL{x}\")\n",
    "    unknow_known_DDS['to_id'] = unknow_known_DDS['to'].map(numId2drugId).apply(lambda x: f\"CHEMBL{x}\")\n",
    "    unknow_known_DDS['from_name'] = unknow_known_DDS['from_id'].map(chmble2drugname)\n",
    "    unknow_known_DDS['to_name'] = unknow_known_DDS['to_id'].map(chmble2drugname)\n",
    "\n",
    "\n",
    "    return unknow_known_DDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDDS = all_nod2vec[all_nod2vec['Type_Interaction']=='DDS']\n",
    "allDDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list of important genes\n",
    "- EGFR (1956),  BCL2 (596), STAT3 (6774),  MYC (4609), BIRC5 (332)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_id = 1956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known interactins\n",
    "DTI_new_a_gene = DTI[DTI['to']==gene_id]\n",
    "DTI_new_a_gene['from_id'] = DTI_new_a_gene['from'].map(numId2drugId).apply(lambda x: f\"CHEMBL{x}\")\n",
    "DTI_new_a_gene['drug_id'] = DTI_new_a_gene['from_id'].map(chmble2drugname)\n",
    "DTI_new_a_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drug can bind\n",
    "print(list(DTI[DTI['to']==gene_id]['from'].map(numId2drugId).apply(lambda x: f\"CHEMBL{x}\").map(chmble2drugname)))\n",
    "# Disease related \n",
    "list(all_nod2vec_new[(all_nod2vec_new['Type_Interaction']=='DisT')& (all_nod2vec_new['to']==gene_id)]['from'].map(numId2dis).map(disid2disname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_682['decreases^expression']['from'].map(chmble2drugname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target_gene=gene_id\n",
    "pre_list = ['decreases^activity', 'decreases^expression', 'decreases^reaction']\n",
    "dic_682 = {}\n",
    "df_all_682 = pd.DataFrame(data={'from': [0], 'to': [0], 'type':[0], 'pro':[0]})\n",
    "repurpusing_682_new = unkown_DTI_labels[unkown_DTI_labels['to']==target_gene] \n",
    "repurpusing_682_new['from'] = repurpusing_682_new['from'].map(numId2drugId).apply(lambda x: f\"CHEMBL{x}\")\n",
    "for i in pre_list:\n",
    "    dic_682[i] = repurpusing_682_new[repurpusing_682_new [i]>=0.5].sort_values(by=[i], ascending=False)\n",
    "    print(dic_682[i][['Pos/Neg','from','to',i]].head(5))\n",
    "    print('')\n",
    "    df_all_682_tmp = dic_682[i][['from','to']]\n",
    "    df_all_682_tmp['type'] = i\n",
    "    df_all_682_tmp['pro'] = dic_682[i][i]\n",
    "    df_all_682 = df_all_682.append(df_all_682_tmp)\n",
    "df_all_682 = df_all_682[1:].sort_values(by=['pro'], ascending=False)\n",
    "df_all_682['drug_name'] = df_all_682.head(50)['from'].map(chmble2drugname)\n",
    "df_all_682.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknow_known_DDS = dds_newdrug(kownDrug=[100506842,100506802, 100506835, 100506881,100506892, 100506727,100506695], num=100)\n",
    "unknow_known_DDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drug with highest similsrity\n",
    "df_all_682[df_all_682['from'].isin(['CHEMBL205596'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drug with highest probability\n",
    "kownDrug = [100506842,100506802, 100506835, 100506881,100506892, 100506727,100506695]\n",
    "newDrugList = [drugId2numId_nod2vec[957]]\n",
    "\n",
    "allDDS[(allDDS['from'].isin(kownDrug)|allDDS['to'].isin(kownDrug)) & (allDDS['to'].isin(newDrugList)|allDDS['from'].isin(newDrugList))].sort_values(by=['weight'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIRC5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known interactins\n",
    "DTI_new_a_gene = DTI[DTI['to']==332]\n",
    "DTI_new_a_gene['from_id'] = DTI_new_a_gene['from'].map(numId2drugId).apply(lambda x: f\"CHEMBL{x}\")\n",
    "DTI_new_a_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drug can bind to BIRC5\n",
    "print(list(DTI[DTI['to']==332]['from'].map(numId2drugId).apply(lambda x: f\"CHEMBL{x}\").map(chmble2drugname)))\n",
    "# Disease related to BIRC5\n",
    "list(all_nod2vec_new[(all_nod2vec_new['Type_Interaction']=='DisT')& (all_nod2vec_new['to']==332)]['from'].map(numId2dis).map(disid2disname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target_gene=332\n",
    "pre_list = ['decreases^activity', 'decreases^expression', 'decreases^reaction']\n",
    "dic_682 = {}\n",
    "df_all_682 = pd.DataFrame(data={'from': [0], 'to': [0], 'type':[0], 'pro':[0]})\n",
    "repurpusing_682_new = unkown_DTI_labels[unkown_DTI_labels['to']==target_gene] \n",
    "repurpusing_682_new['from'] = repurpusing_682_new['from'].map(numId2drugId).apply(lambda x: f\"CHEMBL{x}\")\n",
    "for i in pre_list:\n",
    "    dic_682[i] = repurpusing_682_new[repurpusing_682_new [i]>=0.5].sort_values(by=[i], ascending=False)\n",
    "    print(dic_682[i][['Pos/Neg','from','to',i]].head(5))\n",
    "    print('')\n",
    "    df_all_682_tmp = dic_682[i][['from','to']]\n",
    "    df_all_682_tmp['type'] = i\n",
    "    df_all_682_tmp['pro'] = dic_682[i][i]\n",
    "    df_all_682 = df_all_682.append(df_all_682_tmp)\n",
    "df_all_682 = df_all_682[1:].sort_values(by=['pro'], ascending=False)\n",
    "df_all_682['drug_name'] = df_all_682.head(50)['from'].map(chmble2drugname)\n",
    "df_all_682.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknow_known_DDS = dds_newdrug(kownDrug=[100506842,100506802, 100506835, 100506881,100506892, 100506727,100506695], num=100)\n",
    "unknow_known_DDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drug with highest similsrity\n",
    "df_all_682[df_all_682['from'].isin(['CHEMBL205596'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chmble2drugname['CHEMBL1501']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drug with highest probability\n",
    "kownDrug = [100506842,100506802, 100506835, 100506881,100506892, 100506727,100506695]\n",
    "newDrugList = [drugId2numId_nod2vec[957]]\n",
    "\n",
    "allDDS[(allDDS['from'].isin(kownDrug)|allDDS['to'].isin(kownDrug)) & (allDDS['to'].isin(newDrugList)|allDDS['from'].isin(newDrugList))].sort_values(by=['weight'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rare disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acquired angioedema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESH_Acquired_angioedema = disname2disid['Acquired angioedema']\n",
    "num_Acquired_angioedema = dis2numId[MESH_Acquired_angioedema]\n",
    "print(f'MESH: {MESH_Acquired_angioedema}, numId:{num_Acquired_angioedema}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Acquired_angioedema = DisT_for_diseases_without_drug[DisT_for_diseases_without_drug['from']==100506951]\n",
    "Acquired_angioedema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_gene = 710\n",
    "pre_list = ['increases^activity', 'increases^expression', 'increases^reaction',\n",
    "            'decreases^activity', 'decreases^expression', 'decreases^reaction' ]\n",
    "TH = 0.50\n",
    "\n",
    "repurpusing_710 = drug_reperpusing_dis(embeddings_all, df_unknown_DTI, numId2drugId, drug_cut2chem, dic_model,\n",
    "                         target_gene, pre_list, TH)\n",
    "repurpusing_710"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChEMBL_id to Entrez_id (from uniprot)\n",
    "with open('ChEMBL2Entrez.pkl', 'rb') as f:\n",
    "    ChEMBL2Entrez = pickle.load(f)\n",
    "Entrez2ChEMBL = {y:x for x,y in ChEMBL2Entrez.items()}\n",
    "Entrez2ChEMBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('protein2num.pkl', 'rb') as f:\n",
    "    protein2num = pickle.load(f)\n",
    "    num2pro = {y:x for x,y in protein2num.items()}\n",
    "\n",
    "with open('protein_dict.pkl', 'rb') as f:\n",
    "    protein_dict = pickle.load(f)\n",
    "    \n",
    "df_protein_type = pd.DataFrame(protein_dict.items(), columns=['protein', 'type'])\n",
    "df_protein_type['protein'] = df_protein_type['protein'].map(num2pro)\n",
    "dic_protein_typ = pd.Series(df_protein_type['type'].values, index=df_protein_type['protein']).to_dict()\n",
    "dic_protein_typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list = []\n",
    "heatmap_tmp = new_DTI.reset_index().drop(all_noise).drop(columns=['index'])\n",
    "for i in heatmap_tmp.index:\n",
    "    len_list.append(len(heatmap_tmp['label'][i]))\n",
    "heatmap_tmp['num_label']= len_list\n",
    "print('Number of type of interactions:')\n",
    "heatmap_tmp['num_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Known interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_pos = heatmap_tmp[['from', 'to', 'num_label']]\n",
    "heatmap_pos['Chembl']= heatmap_pos['from'].map(numId2drugId).apply(lambda x: f\"CHEMBL{x}\")\n",
    "heatmap_pos = heatmap_pos.drop(columns=['from'])\n",
    "heatmap_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### known negative interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (100--> negative)\n",
    "heatmap_neg = negative_DTI[['Chembl','to']]\n",
    "heatmap_neg['num_label']= 100\n",
    "heatmap_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unkown postive prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_unkown = unkown_DTI_labels[['from','to']+selected_type]\n",
    "for i in selected_type:\n",
    "    heatmap_unkown.loc[heatmap_unkown[i] > 0.6, i] = 'pos'\n",
    "    heatmap_unkown.loc[heatmap_unkown[i] != 'pos', i] = 'neg'\n",
    "    heatmap_unkown.loc[heatmap_unkown[i] == 'pos', i] = -1\n",
    "    heatmap_unkown.loc[heatmap_unkown[i] == 'neg', i] = 0\n",
    "heatmap_unkown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 --> not in our label --> postive but diffrent postive type like binding\n",
    "heatmap_unkown['num_label']= heatmap_unkown[selected_type].sum(axis=1)\n",
    "heatmap_unkown['num_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_unkown.loc[heatmap_unkown['num_label'] <= -4, 'num_label'] = 0\n",
    "heatmap_unkown['num_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## both --> increase and deacrse--> change the waGE DTIs to unavailbe or 0\n",
    "wag_DTIs = heatmap_unkown.copy()\n",
    "wag_DTIs['expresstion'] = wag_DTIs[['increases^expression','decreases^expression']].sum(axis=1)\n",
    "wag_DTIs['reaction'] = wag_DTIs[['increases^reaction','decreases^reaction']].sum(axis=1)\n",
    "wag_DTIs['activity'] = wag_DTIs[['increases^activity','decreases^activity']].sum(axis=1)\n",
    "\n",
    "wag_DTIs.loc[wag_DTIs['reaction'] == -2, 'num_label'] = 0\n",
    "wag_DTIs.loc[wag_DTIs['activity'] == -2, 'num_label'] = 0\n",
    "wag_DTIs.loc[wag_DTIs['expresstion'] == -2, 'num_label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_perdict = wag_DTIs [['from','to', 'num_label']]\n",
    "heatmap_perdict['Chembl'] = heatmap_perdict['from'].map(numId2drugId).apply(lambda x: f\"CHEMBL{x}\")\n",
    "heatmap_perdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unkown Negative interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_notHP = vector_unknown_DTI_label[~vector_unknown_DTI_label.index.isin(heatmap_perdict.index)][['from', 'to']]\n",
    "negative_notHP['num_label']= -100\n",
    "negative_notHP['Chembl'] = negative_notHP['from'].map(numId2drugId).apply(lambda x: f\"CHEMBL{x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_protein = ['unclassified_protein', 'Trascription_factor', 'Transporter', 'Secreted_protein',\n",
    "                   'other_categories', 'membrance_receptor', 'Ion_Channel', 'Epigenetic_regulation', \n",
    "                    'Enzyme_Cytochrome P450', 'Cytosolic_protein', 'Enzyme_Hydrolase', 'Enzyme_Kinase',\n",
    "                    'Enzyme_Ligase','Enzyme_Lyase','Enzyme_Oxidoreductase','Enzyme_Phosphatase',\n",
    "                    'Enzyme_Protease', 'Enzyme_rest', 'Enzyme_Transferase']\n",
    "\n",
    "protein_type = {}\n",
    "for p in list_protein:\n",
    "    df_p = pd.read_csv(f'{p}.csv')\n",
    "    df_p['type_protein'] = p\n",
    "dict_protein = pd.Series(df_p['type_protein'].values, index = df_p['ChEMBL ID']).to_dict()\n",
    "dict_protein['CHEMBL2055'] = 'Trascription_factor'\n",
    "dict_protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All interactions \n",
    "final_heatmap = (negative_notHP.append(heatmap_perdict)).append(heatmap_pos.append(heatmap_neg))[['Chembl','to','num_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_heatmap = final_heatmap.rename(columns={\"Chembl\": \"from_ChEMBL\", \"to\": \"to_ChEMBL\", 'num_label':'label'})\n",
    "final_heatmap.loc[final_heatmap['label'] == 100, 'label'] = 4\n",
    "final_heatmap.loc[final_heatmap['label'] == -100, 'label'] = -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_int='label'\n",
    "list_DTI = final_heatmap[['from_ChEMBL','to_ChEMBL',type_int]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "cols = list(set([x[1] for x in list_DTI]))\n",
    "for elem in list_DTI:\n",
    "    result_dict[elem[0]] = [0]*len(cols)\n",
    "\n",
    "for elem in list_DTI:\n",
    "    col_idx = cols.index(elem[1])    \n",
    "    result_dict[elem[0]][col_idx] = elem[2]\n",
    "\n",
    "df_heatmap = pd.DataFrame.from_dict(result_dict, orient='index', columns=cols)\n",
    "df_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list_target = ['#58ACFA','#FF1493', 'yellow','orange', '#00CED1','#5F9EA0','#006400','#96bf65','#fcc808','#7b2b48',\n",
    " '#e96957','#e06000','#173679','#d2dd49','#684a6b','#096eb2','#ce482a', 'red', 'lime', 'lightslategray',\n",
    "                                      'olive', 'rosybrown', 'sienna', 'darkmagenta','midnightblue','maroon',\n",
    "                                      'lightcoral','gold','sandybrown','tomato','lawngreen','lightgreen','darkorchid',\n",
    "                                      'lightskyblue','darkgreen']\n",
    "color_list_drug = ['mediumvioletred','mediumblue','gold','green','violet','mediumturquoise','mediumvioletred','darkgoldenrod','pink','dimgray']\n",
    "df_hetmap_tmp = df_heatmap.copy()\n",
    "df_hetmap_tmp = df_hetmap_tmp.T\n",
    "df_hetmap_tmp['target_color']= df_hetmap_tmp.index.map(Entrez2ChEMBL).map(dic_protein_typ)\n",
    "df_hetmap_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_heatmap['label'].value_counts()\n",
    "# -4 negative prediction\n",
    "# 4 known negative\n",
    "# 0 positive but not in our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=0.7)\n",
    "# discrete colormap (n samples from a given cmap)\n",
    "cmap = ['#F5EEF8','#1F618D', '#2E86C1','#85C1E9', 'lightgray','#F5B7B1','#EC7063','#CB4335','#5B2C6F']\n",
    "plot = sns.clustermap(df_heatmap, row_cluster=True, col_cluster=True, cmap=cmap, figsize=(30, 30)) \n",
    "ax = plot.ax_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustermap(final_DTI, type_int, order= False):   \n",
    "    list_DTI = final_DTI[['from_ChEMBL','to_ChEMBL',type_int]].values.tolist()\n",
    "\n",
    "    result_dict = {}\n",
    "    cols = list(set([x[1] for x in list_DTI]))\n",
    "    for elem in list_DTI:\n",
    "        result_dict[elem[0]] = [0]*len(cols)\n",
    "\n",
    "    for elem in list_DTI:\n",
    "        col_idx = cols.index(elem[1])    \n",
    "        result_dict[elem[0]][col_idx] = elem[2]\n",
    "\n",
    "    df_heatmap = pd.DataFrame.from_dict(result_dict, orient='index', columns=cols)\n",
    "    \n",
    "    color_list_target = ['#58ACFA','#FF1493', 'yellow','orange', '#00CED1','#5F9EA0','#006400','#96bf65','#fcc808','#7b2b48',\n",
    " '#e96957','#e06000','#173679','#d2dd49','#684a6b','#096eb2','#ce482a', 'red', 'lime', 'lightslategray',\n",
    "                                      'olive', 'rosybrown', 'sienna', 'darkmagenta','midnightblue','maroon',\n",
    "                                      'lightcoral','gold','sandybrown','tomato','lawngreen','lightgreen','darkorchid',\n",
    "                                      'lightskyblue','darkgreen']\n",
    "    color_list_drug = ['mediumvioletred','mediumblue','gold','green','violet','mediumturquoise','mediumvioletred','darkgoldenrod','pink','dimgray']\n",
    "    df_hetmap_tmp = df_heatmap.copy()\n",
    "    df_hetmap_tmp = df_hetmap_tmp.T\n",
    "    #df_hetmap_tmp['target_color']= df_hetmap_tmp.index.map(Lou_target_new)\n",
    "    df_hetmap_tmp['target_color']= df_hetmap_tmp.index.map(type_target_new)\n",
    "    df_hetmap_tmp = df_hetmap_tmp.sort_values(by='target_color').drop(columns='target_color').T\n",
    "    df_hetmap_tmp['index_id2']= df_heatmap.index.map(Lou_drug_new)\n",
    "    df_hetmap_tmp = df_hetmap_tmp.sort_values(by='index_id2').drop(columns='index_id2')\n",
    "    df_heatmap = df_hetmap_tmp.copy()\n",
    "\n",
    "    df_hetmap_tmp['index_id']= df_hetmap_tmp.index\n",
    "    my_palette_drug= dict(zip(df_hetmap_tmp.index_id.map(Lou_drug_new).astype(str).unique(),color_list_drug))\n",
    "    row_colors_drug = df_hetmap_tmp.index_id.map(Lou_drug_new).astype(str).map(my_palette_drug)\n",
    "\n",
    "    color_dict = {}\n",
    "    #my_palette_target= dict(zip(set(list(df_hetmap_tmp.rename(columns=Lou_target_new))),color_list_target))\n",
    "    my_palette_target= dict(zip(set(list(df_hetmap_tmp.rename(columns=type_target_new))),color_list_target))\n",
    "\n",
    "\n",
    "    df_hetmap_tmp = df_hetmap_tmp.drop(columns=['index_id'])\n",
    "    for x in list(df_hetmap_tmp):\n",
    "        #color_dict[x] = my_palette_target[Lou_target_new[x]]\n",
    "        color_dict[x] = my_palette_target[type_target_new[x]]\n",
    "\n",
    "    df_hetmap_tmp = df_hetmap_tmp.append(pd.Series(color_dict),ignore_index=True)\n",
    "    col_colors_target = df_hetmap_tmp[548:].squeeze()\n",
    "\n",
    "    value_to_int = {'Positive_P': 0, 'Positive': 1, 'Weak': 2, 'Negative_P': 3, 'Negative': 4}\n",
    "    n = len(value_to_int)     \n",
    "    sns.set(font_scale=0.7)\n",
    "    # discrete colormap (n samples from a given cmap)\n",
    "    cmap = [(173/255, 216/255, 230/255), (0, 0, 139/255), (224/255, 255/255, 255/255), (255/255, 192/255, 203/255), (220/255, 20/255, 60/255)]\n",
    "    plot = sns.clustermap(df_heatmap.replace(value_to_int),row_cluster=order, col_cluster=order, cmap=cmap, row_colors=row_colors_drug, col_colors=col_colors_target, figsize=(20, 20)) \n",
    "\n",
    "    ax = plot.ax_heatmap\n",
    "\n",
    "    plot.ax_row_dendrogram.set_visible(False)\n",
    "    plot.ax_col_dendrogram.set_visible(False)\n",
    "    plot.cax.set_visible(False)\n",
    "    # modify colorbar:\n",
    "    colorbar = ax.collections[0].colorbar \n",
    "    r = colorbar.vmax - colorbar.vmin \n",
    "    colorbar.set_ticks([colorbar.vmin + r / n * (0.5 + i) for i in range(n)])\n",
    "    colorbar.set_ticklabels(list(value_to_int.keys())) \n",
    "    \n",
    "    plot.savefig(\"clustermap.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
